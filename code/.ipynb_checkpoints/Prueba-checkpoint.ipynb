{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a0d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d86c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "train_path = r'C:\\Users\\alvar\\Desktop\\UCM-TFM-G1\\data\\LLM\\waste-classification\\train.csv'\n",
    "test_path = r'C:\\Users\\alvar\\Desktop\\UCM-TFM-G1\\data\\LLM\\waste-classification\\test.csv'\n",
    "validation_path = r'C:\\Users\\alvar\\Desktop\\UCM-TFM-G1\\data\\LLM\\waste-classification\\validation.csv'\n",
    "\n",
    "# Read the CSV files into DataFrames with the first column as the index\n",
    "train_df = pd.read_csv(train_path, index_col=0)\n",
    "test_df = pd.read_csv(test_path, index_col=0)\n",
    "validation_df = pd.read_csv(validation_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61af5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43137</th>\n",
       "      <td>Where should I put a tobacco pack</td>\n",
       "      <td>TOBACCO PACK</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36464</th>\n",
       "      <td>Where do I throw my seasoning packets</td>\n",
       "      <td>CONDIMENT PACKETS</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23615</th>\n",
       "      <td>In which bin should I throw my metro ticket ?</td>\n",
       "      <td>TRANSPORT TICKET</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Can I recycle this throwaway cup ?</td>\n",
       "      <td>PAPER CUP</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>Excuse me, can you help me ? I have to throw a...</td>\n",
       "      <td>GLASS BOTTLE</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36273</th>\n",
       "      <td>Where do I throw a guinness can</td>\n",
       "      <td>ALUMINIUM CAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>Where can I throw this aquafina plastic bottle ?</td>\n",
       "      <td>PLASTIC BOTTLE</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16076</th>\n",
       "      <td>I have my chi, where should I throw it ?</td>\n",
       "      <td>PAPER MAGASINE</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42830</th>\n",
       "      <td>Where should I put my disposable cup</td>\n",
       "      <td>PLASTIC CUP</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22298</th>\n",
       "      <td>In which bin should I throw my canada dry can ?</td>\n",
       "      <td>ALUMINIUM CAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27561 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Phrase              Class  \\\n",
       "43137                  Where should I put a tobacco pack       TOBACCO PACK   \n",
       "36464              Where do I throw my seasoning packets  CONDIMENT PACKETS   \n",
       "23615      In which bin should I throw my metro ticket ?   TRANSPORT TICKET   \n",
       "736                   Can I recycle this throwaway cup ?          PAPER CUP   \n",
       "4569   Excuse me, can you help me ? I have to throw a...       GLASS BOTTLE   \n",
       "...                                                  ...                ...   \n",
       "36273                    Where do I throw a guinness can      ALUMINIUM CAN   \n",
       "33019   Where can I throw this aquafina plastic bottle ?     PLASTIC BOTTLE   \n",
       "16076           I have my chi, where should I throw it ?     PAPER MAGASINE   \n",
       "42830               Where should I put my disposable cup        PLASTIC CUP   \n",
       "22298    In which bin should I throw my canada dry can ?      ALUMINIUM CAN   \n",
       "\n",
       "       Class_index  \n",
       "43137         49.0  \n",
       "36464          6.0  \n",
       "23615         46.0  \n",
       "736           19.0  \n",
       "4569          11.0  \n",
       "...            ...  \n",
       "36273          0.0  \n",
       "33019         29.0  \n",
       "16076         20.0  \n",
       "42830         32.0  \n",
       "22298          0.0  \n",
       "\n",
       "[27561 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087de9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'intents.json' creado y guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "intents_data ={\"intents\": [\n",
    "    {\"tag\": \"greeting\",\n",
    "     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n",
    "     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n",
    "    },\n",
    "    {\"tag\": \"goodbye\",\n",
    "     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n",
    "    },\n",
    "    {\"tag\": \"thanks\",\n",
    "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n",
    "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n",
    "    },\n",
    "    {\"tag\": \"about\",\n",
    "     \"patterns\": [\"Who are you?\", \"What are you?\", \"Who you are?\" ],\n",
    "     \"responses\": [\"I.m Joana, your bot assistant\", \"I'm Joana, an Artificial Intelligent bot\"]\n",
    "    },\n",
    "    {\"tag\": \"name\",\n",
    "    \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\"],\n",
    "    \"responses\": [\"You can call me Joana.\", \"I'm Joana!\", \"Just call me as Joana\"]\n",
    "    },\n",
    "    {\"tag\": \"help\",\n",
    "    \"patterns\": [\"Could you help me?\", \"give me a hand please\", \"Can you help?\", \"What can you do for me?\", \"I need a support\", \"I need a help\", \"support me please\"],\n",
    "    \"responses\": [\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\"]\n",
    "    },\n",
    "    {\"tag\": \"createaccount\",\n",
    "    \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \"can you create an account for me\", \"how to open a new account\"],\n",
    "    \"responses\": [\"You can just easily create a new account from our web site\", \"Just go to our web site and follow the guidelines to create a new account\"]\n",
    "    },\n",
    "    {\"tag\": \"complaint\",\n",
    "    \"patterns\": [\"have a complaint\", \"I want to raise a complaint\", \"there is a complaint about a service\"],\n",
    "    \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"]\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "# Guardar el contenido en un archivo JSON\n",
    "with open('intents.json', 'w') as json_file:\n",
    "    json.dump(intents_data, json_file, indent=4)\n",
    "\n",
    "print(\"Archivo 'intents.json' creado y guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d81b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f181ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc6d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1280)\n",
      "    (wpe): Embedding(1024, 1280)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-35): 36 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 50\n",
    "\n",
    "# Set up GPT-2 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Set a padding token\n",
    "\n",
    "# Set up GPT-2 model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "sequences = tokenizer(training_sentences, padding=True, truncation=True, return_tensors=\"tf\", max_length=max_len)\n",
    "padded_sequences = pad_sequences(sequences[\"input_ids\"], truncating='post', maxlen=max_len)\n",
    "\n",
    "# Print GPT-2 model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ec15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained(\"chat_model\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a0c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: Hi\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential/embedding/embedding_lookup defined at (most recent call last):\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\", line 55, in <module>\n\n  File \"C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\", line 44, in chat\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[0,0] = 17250 is not in [0, 1000)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_2893]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYELLOW\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Start messaging with the bot (type quit to stop)!\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mStyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRESET_ALL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\u001b[0m in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# Predict using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Get the predicted tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential/embedding/embedding_lookup defined at (most recent call last):\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\", line 55, in <module>\n\n  File \"C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_13736\\290513283.py\", line 44, in chat\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\alvar\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[0,0] = 17250 is not in [0, 1000)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_2893]"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        # Use GPT-2 tokenizer's encode method\n",
    "        input_sequence = tokenizer.encode(inp, return_tensors=\"tf\")\n",
    "\n",
    "        # Ensure that token indices are within the model's vocabulary size\n",
    "        input_sequence = np.clip(input_sequence, 0, tokenizer.vocab_size)\n",
    "\n",
    "        # Predict using the model\n",
    "        result = model.predict(input_sequence)\n",
    "\n",
    "        # Get the predicted tag\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL, np.random.choice(i['responses']))\n",
    "\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0aeadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
